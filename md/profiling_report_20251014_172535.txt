============================================================
RELATÓRIO DE PROFILING DO YAKE
============================================================
Data: 2025-10-14 17:25:35

FERRAMENTAS USADAS:
  - cProfile: SIM
  - pyinstrument: SIM
  - line_profiler: NÃO
  - memory_profiler: NÃO

RESULTADOS DE PERFORMANCE:

PEQUENO:
  Tamanho: 3.1KB
  Tempo: 0.022s
  Keywords: 50

MÉDIO:
  Tamanho: 30.6KB
  Tempo: 0.146s
  Keywords: 50

GRANDE:
  Tamanho: 122.5KB
  Tempo: 0.496s
  Keywords: 50

============================================================
RESULTADOS DETALHADOS DO PROFILING:
============================================================


--- cProfile ---

         636403 function calls (636273 primitive calls) in 0.324 seconds

   Ordered by: cumulative time
   List reduced from 212 to 20 due to restriction <20>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.324    0.324 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\core\yake.py:307(extract_keywords)
        1    0.000    0.000    0.314    0.314 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:33(__init__)
        1    0.000    0.000    0.314    0.314 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:164(_build)
      250    0.009    0.000    0.247    0.001 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:196(_process_sentence)
     3600    0.010    0.000    0.233    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:251(_process_word)
     3600    0.020    0.000    0.114    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:321(_generate_candidates)
        1    0.002    0.002    0.067    0.067 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\utils.py:64(tokenize_sentences)
     3600    0.002    0.000    0.062    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:361(get_tag)
     3600    0.013    0.000    0.059    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\utils.py:95(get_tag)
    10050    0.032    0.000    0.044    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\composed_word.py:31(__init__)
    10050    0.021    0.000    0.044    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:545(add_or_update_composedword)
    11057    0.016    0.000    0.041    0.000 {built-in method builtins.sum}
      250    0.001    0.000    0.035    0.000 C:\Python312\Lib\site-packages\segtok\tokenizer.py:280(web_tokenizer)
      250    0.004    0.000    0.028    0.000 C:\Python312\Lib\site-packages\segtok\tokenizer.py:185(word_tokenizer)
     3600    0.006    0.000    0.027    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:298(_update_cooccurrence)
     4101    0.025    0.000    0.025    0.000 {method 'split' of '_regex.Pattern' objects}
      252    0.001    0.000    0.022    0.000 C:\Python312\Lib\site-packages\segtok\segmenter.py:254(_sentences)
     3350    0.007    0.000    0.019    0.000 C:\Users\Tiago\Documents\GitHub\yake-2.0\yake\data\core.py:521(add_cooccur)
      252    0.000    0.000    0.018    0.000 C:\Python312\Lib\site-packages\segtok\segmenter.py:287(_abbreviation_joiner)
      747    0.017    0.000    0.017    0.000 {method 'search' of '_regex.Pattern' objects}





--- pyinstrument ---


  _     ._   __/__   _ _  _  _ _/_   Recorded: 17:25:34  Samples:  260
 /_//_/// /_\ / //_// / //_'/ //     Duration: 0.255     CPU time: 0.094
/   _/                      v5.1.1

Profile at C:\Users\Tiago\Documents\GitHub\yake-2.0\comprehensive_profiling.py:151

0.262 profile_with_pyinstrument  comprehensive_profiling.py:140
└─ 0.260 KeywordExtractor.extract_keywords  yake\core\yake.py:307
   ├─ 0.252 DataCore.__init__  yake\data\core.py:33
   │  └─ 0.252 DataCore._build  yake\data\core.py:164
   │     ├─ 0.189 DataCore._process_sentence  yake\data\core.py:196
   │     │  ├─ 0.178 DataCore._process_word  yake\data\core.py:251
   │     │  │  ├─ 0.094 DataCore._generate_candidates  yake\data\core.py:321
   │     │  │  │  ├─ 0.043 ComposedWord.__init__  yake\data\composed_word.py:31
   │     │  │  │  │  ├─ 0.029 [self]  yake\data\composed_word.py
   │     │  │  │  │  ├─ 0.007 str.join  <built-in>
   │     │  │  │  │  ├─ 0.003 str.lower  <built-in>
   │     │  │  │  │  └─ 0.003 len  <built-in>
   │     │  │  │  ├─ 0.034 DataCore.add_or_update_composedword  yake\data\core.py:545
   │     │  │  │  │  ├─ 0.022 [self]  yake\data\core.py
   │     │  │  │  │  ├─ 0.006 DataCore.candidates  yake\data\core.py:138
   │     │  │  │  │  └─ 0.003 ComposedWord.update_cand  yake\data\composed_word.py:142
   │     │  │  │  └─ 0.012 [self]  yake\data\core.py
   │     │  │  ├─ 0.040 DataCore.get_tag  yake\data\core.py:361
   │     │  │  │  └─ 0.040 get_tag  yake\data\utils.py:95
   │     │  │  │     ├─ 0.015 [self]  yake\data\utils.py
   │     │  │  │     ├─ 0.012 <genexpr>  yake\data\utils.py:126
   │     │  │  │     │  ├─ 0.009 [self]  yake\data\utils.py
   │     │  │  │     │  └─ 0.003 str.isalpha  <built-in>
   │     │  │  │     ├─ 0.007 <genexpr>  yake\data\utils.py:125
   │     │  │  │     │  ├─ 0.004 [self]  yake\data\utils.py
   │     │  │  │     │  └─ 0.003 str.isdigit  <built-in>
   │     │  │  │     └─ 0.005 <genexpr>  yake\data\utils.py:127
   │     │  │  ├─ 0.023 DataCore._update_cooccurrence  yake\data\core.py:298
   │     │  │  │  ├─ 0.016 DataCore.add_cooccur  yake\data\core.py:521
   │     │  │  │  │  ├─ 0.007 [self]  yake\data\core.py
   │     │  │  │  │  └─ 0.005 DiGraph.__getitem__  networkx\classes\graph.py:489
   │     │  │  │  │     └─ 0.004 AdjacencyView.__getitem__  networkx\classes\coreviews.py:80
   │     │  │  │  ├─ 0.004 [self]  yake\data\core.py
   │     │  │  │  └─ 0.003 max  <built-in>
   │     │  │  ├─ 0.009 DataCore.get_term  yake\data\core.py:470
   │     │  │  ├─ 0.008 [self]  yake\data\core.py
   │     │  │  └─ 0.003 SingleWord.add_occur  yake\data\single_word.py:292
   │     │  └─ 0.009 [self]  yake\data\core.py
   │     └─ 0.063 tokenize_sentences  yake\data\utils.py:64
   │        ├─ 0.027 _sentences  segtok\segmenter.py:254
   │        │     [3 frames hidden]  segtok, <built-in>
   │        ├─ 0.024 web_tokenizer  segtok\tokenizer.py:280
   │        │     [3 frames hidden]  segtok, <built-in>
   │        ├─ 0.007 split_contractions  segtok\tokenizer.py:122
   │        │  └─ 0.005 Pattern.match  <built-in>
   │        └─ 0.003 [self]  yake\data\utils.py
   ├─ 0.004 DataCore.build_single_terms_features  yake\data\core.py:419
   │  └─ 0.004 SingleWord.update_h  yake\data\single_word.py:233
   └─ 0.003 KeywordExtractor._optimized_medium_dedup  yake\core\yake.py:411



