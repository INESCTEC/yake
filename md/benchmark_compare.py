#!/usr/bin/env python3
# pylint: skip-file
"""
ğŸ“Š COMPARAÃ‡ÃƒO DE VERSÃ•ES DO YAKE
=================================
Script para comparar performance entre diferentes versÃµes
"""

import sys
import time
import json
from datetime import datetime
from pathlib import Path

def benchmark_version(text, version_name="atual"):
    """Benchmark de uma versÃ£o especÃ­fica"""
    
    import yake
    
    times = []
    keywords_list = []
    
    # 5 execuÃ§Ãµes para obter mÃ©dia mais precisa
    for i in range(5):
        start = time.perf_counter()
        
        kw_extractor = yake.KeywordExtractor(
            lan='en',
            n=3,
            dedupLim=0.7,
            top=50
        )
        keywords = kw_extractor.extract_keywords(text)
        
        elapsed = time.perf_counter() - start
        times.append(elapsed)
        keywords_list.append(len(keywords))
    
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)
    std_dev = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
    
    return {
        'version': version_name,
        'times': times,
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time,
        'std_dev': std_dev,
        'keywords_count': keywords_list[0],
        'text_size': len(text)
    }

def get_test_texts():
    """Retorna conjunto de textos de teste"""
    
    base_texts = [
        """Machine learning algorithms revolutionize artificial intelligence 
        by enabling systems to learn from data patterns.""",
        
        """Climate change causes rising temperatures and extreme weather 
        events threatening ecosystems worldwide.""",
        
        """Quantum computing uses quantum mechanics phenomena like 
        superposition for information processing.""",
    ]
    
    return {
        'pequeno': "\n\n".join(base_texts * 5),
        'mÃ©dio': "\n\n".join(base_texts * 50),
        'grande': "\n\n".join(base_texts * 200),
    }

def compare_versions():
    """Compara mÃºltiplas versÃµes"""
    
    print("ğŸ“Š COMPARAÃ‡ÃƒO DE VERSÃ•ES DO YAKE")
    print("=" * 70)
    print(f"ğŸ“… Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    texts = get_test_texts()
    
    all_results = {}
    
    for text_name, text in texts.items():
        text_size_kb = len(text.encode('utf-8')) / 1024
        
        print(f"\nğŸ” Testando com texto {text_name} ({text_size_kb:.1f}KB)")
        print("-" * 70)
        
        result = benchmark_version(text, "versÃ£o atual")
        all_results[text_name] = result
        
        print(f"â±ï¸  Tempo mÃ©dio: {result['avg_time']:.4f}s")
        print(f"   Min: {result['min_time']:.4f}s | Max: {result['max_time']:.4f}s")
        print(f"   Desvio padrÃ£o: {result['std_dev']:.4f}s")
        print(f"   VariaÃ§Ã£o: {((result['max_time'] - result['min_time']) / result['avg_time'] * 100):.1f}%")
        print(f"ğŸ“Š Keywords extraÃ­das: {result['keywords_count']}")
    
    return all_results

def display_comparison_table(results):
    """Exibe tabela comparativa"""
    
    print("\n" + "=" * 70)
    print("ğŸ“Š TABELA COMPARATIVA")
    print("=" * 70)
    print()
    
    print("â”Œ" + "â”€"*12 + "â”¬" + "â”€"*14 + "â”¬" + "â”€"*16 + "â”¬" + "â”€"*14 + "â”")
    print("â”‚ Tamanho    â”‚ Tamanho (KB) â”‚ Tempo MÃ©dio (s) â”‚ Keywords     â”‚")
    print("â”œ" + "â”€"*12 + "â”¼" + "â”€"*14 + "â”¼" + "â”€"*16 + "â”¼" + "â”€"*14 + "â”¤")
    
    for text_name, result in results.items():
        size_kb = result['text_size'] / 1024
        print(f"â”‚ {text_name:<10} â”‚ {size_kb:>11.1f}K â”‚ {result['avg_time']:>14.4f} â”‚ {result['keywords_count']:>12} â”‚")
    
    print("â””" + "â”€"*12 + "â”´" + "â”€"*14 + "â”´" + "â”€"*16 + "â”´" + "â”€"*14 + "â”˜")

def analyze_scalability(results):
    """Analisa escalabilidade"""
    
    print("\n" + "=" * 70)
    print("ğŸ“ˆ ANÃLISE DE ESCALABILIDADE")
    print("=" * 70)
    print()
    
    sizes = list(results.keys())
    
    for i in range(1, len(sizes)):
        prev_size = sizes[i-1]
        curr_size = sizes[i]
        
        prev = results[prev_size]
        curr = results[curr_size]
        
        size_ratio = curr['text_size'] / prev['text_size']
        time_ratio = curr['avg_time'] / prev['avg_time']
        
        print(f"ğŸ” {prev_size.capitalize()} â†’ {curr_size.capitalize()}")
        print(f"   Aumento de tamanho: {size_ratio:.2f}x")
        print(f"   Aumento de tempo: {time_ratio:.2f}x")
        
        if time_ratio < size_ratio:
            efficiency = ((size_ratio - time_ratio) / size_ratio) * 100
            print(f"   âœ… Sub-linear! {efficiency:.1f}% mais eficiente que linear")
        elif time_ratio < size_ratio * 1.2:
            print(f"   âš ï¸  Aproximadamente linear")
        else:
            overhead = ((time_ratio / size_ratio) - 1) * 100
            print(f"   âŒ Super-linear! {overhead:.1f}% overhead")
        print()

def save_benchmark_results(results):
    """Salva resultados em JSON para comparaÃ§Ã£o futura"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"benchmark_{timestamp}.json"
    
    # Preparar dados para JSON
    json_data = {
        'timestamp': timestamp,
        'date': datetime.now().isoformat(),
        'results': {}
    }
    
    for text_name, result in results.items():
        json_data['results'][text_name] = {
            'avg_time': result['avg_time'],
            'min_time': result['min_time'],
            'max_time': result['max_time'],
            'std_dev': result['std_dev'],
            'keywords_count': result['keywords_count'],
            'text_size_bytes': result['text_size'],
            'times': result['times']
        }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, indent=2)
    
    print(f"\nğŸ’¾ Resultados salvos em: {filename}")
    print(f"   Use este arquivo para comparar com futuras otimizaÃ§Ãµes!")
    
    return filename

def compare_with_previous(current_results):
    """Compara com benchmark anterior se existir"""
    
    print("\n" + "=" * 70)
    print("ğŸ”„ COMPARAÃ‡ÃƒO COM BENCHMARKS ANTERIORES")
    print("=" * 70)
    print()
    
    # Procurar arquivos de benchmark anteriores
    benchmark_files = sorted(Path('.').glob('benchmark_*.json'))
    
    if len(benchmark_files) < 2:
        print("â„¹ï¸  Nenhum benchmark anterior encontrado para comparaÃ§Ã£o")
        print("   Execute este script novamente apÃ³s fazer otimizaÃ§Ãµes!")
        return
    
    # Pegar penÃºltimo arquivo (anterior ao que acabamos de criar)
    previous_file = benchmark_files[-2]
    
    print(f"ğŸ“„ Comparando com: {previous_file.name}")
    print()
    
    with open(previous_file, 'r', encoding='utf-8') as f:
        previous_data = json.load(f)
    
    previous_results = previous_data['results']
    
    print("â”Œ" + "â”€"*12 + "â”¬" + "â”€"*16 + "â”¬" + "â”€"*16 + "â”¬" + "â”€"*14 + "â”")
    print("â”‚ Tamanho    â”‚ Tempo Anterior  â”‚ Tempo Atual     â”‚ MudanÃ§a      â”‚")
    print("â”œ" + "â”€"*12 + "â”¼" + "â”€"*16 + "â”¼" + "â”€"*16 + "â”¼" + "â”€"*14 + "â”¤")
    
    improvements = []
    
    for text_name in current_results.keys():
        if text_name in previous_results:
            prev_time = previous_results[text_name]['avg_time']
            curr_time = current_results[text_name]['avg_time']
            
            diff = curr_time - prev_time
            diff_pct = (diff / prev_time) * 100
            
            improvements.append(diff_pct)
            
            # Emoji baseado na mudanÃ§a
            if diff_pct < -5:
                emoji = "âœ…"
            elif diff_pct < 5:
                emoji = "â–"
            else:
                emoji = "âŒ"
            
            print(f"â”‚ {text_name:<10} â”‚ {prev_time:>13.4f}s â”‚ {curr_time:>13.4f}s â”‚ {emoji} {diff_pct:>+7.1f}% â”‚")
    
    print("â””" + "â”€"*12 + "â”´" + "â”€"*16 + "â”´" + "â”€"*16 + "â”´" + "â”€"*14 + "â”˜")
    
    if improvements:
        avg_improvement = sum(improvements) / len(improvements)
        
        print()
        if avg_improvement < -5:
            print(f"ğŸ‰ Ã“timo! Melhoria mÃ©dia de {-avg_improvement:.1f}%")
        elif avg_improvement < 5:
            print(f"â– Sem mudanÃ§a significativa ({avg_improvement:+.1f}%)")
        else:
            print(f"âš ï¸  RegressÃ£o! Piora mÃ©dia de {avg_improvement:.1f}%")

def main():
    """FunÃ§Ã£o principal"""
    
    try:
        # 1. Executar benchmarks
        results = compare_versions()
        
        # 2. Exibir tabela comparativa
        display_comparison_table(results)
        
        # 3. Analisar escalabilidade
        analyze_scalability(results)
        
        # 4. Salvar resultados
        benchmark_file = save_benchmark_results(results)
        
        # 5. Comparar com anterior
        compare_with_previous(results)
        
        print("\n" + "=" * 70)
        print("âœ… BENCHMARK CONCLUÃDO!")
        print("=" * 70)
        print()
        print("ğŸ’¡ PrÃ³ximos passos:")
        print("   1. Implemente uma otimizaÃ§Ã£o")
        print("   2. Execute este script novamente")
        print("   3. Compare os resultados automaticamente")
        print("   4. Valide se a otimizaÃ§Ã£o funcionou!")
        print()
        
    except Exception as e:
        print(f"\nâŒ Erro durante benchmark: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
