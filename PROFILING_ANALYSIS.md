ğŸ¯ ANÃLISE DOS RESULTADOS DO PROFILING
=======================================

## ğŸ“Š Resumo da Performance

### Escalabilidade
```
Tamanho    | KB    | Tempo (s) | Crescimento
-----------|-------|-----------|-------------
Pequeno    | 3.1   | 0.022     | baseline
MÃ©dio      | 30.6  | 0.146     | 6.6x
Grande     | 122.5 | 0.496     | 22.5x
```

**AnÃ¡lise:** 
- Crescimento de 10x no tamanho â†’ 6.6x no tempo (pequenoâ†’mÃ©dio)
- Crescimento de 4x no tamanho â†’ 3.4x no tempo (mÃ©dioâ†’grande)
- âœ… Escalabilidade sub-linear (boa performance!)

---

## ğŸ”¥ HOTSPOTS PRINCIPAIS (funÃ§Ãµes mais lentas)

### Top 5 FunÃ§Ãµes por Tempo Total (cProfile)

1. **extract_keywords** (0.324s total, 100%)
   - FunÃ§Ã£o principal - tempo esperado
   
2. **DataCore.__init__ / _build** (0.314s, 97%)
   - ConstruÃ§Ã£o da estrutura de dados
   - Aqui estÃ¡ o trabalho real!
   
3. **_process_sentence** (0.247s, 76%)
   - 250 chamadas â†’ 0.988ms por sentenÃ§a
   - Processa cada sentenÃ§a do texto
   
4. **_process_word** (0.233s, 72%)
   - 3600 chamadas â†’ 0.065ms por palavra
   - Processa cada palavra encontrada
   
5. **_generate_candidates** (0.114s, 35%)
   - 3600 chamadas â†’ 0.032ms por palavra
   - Gera candidatos n-gram

---

## ğŸ¯ ANÃLISE DETALHADA (pyinstrument)

### Hierarquia de Tempo

```
extract_keywords (0.260s)
â”‚
â””â”€ DataCore._build (0.252s, 97%)
   â”‚
   â”œâ”€ _process_sentence (0.189s, 73%)
   â”‚  â”‚
   â”‚  â””â”€ _process_word (0.178s, 68%)
   â”‚     â”‚
   â”‚     â”œâ”€ _generate_candidates (0.094s, 36%)
   â”‚     â”‚  â”œâ”€ ComposedWord.__init__ (0.043s, 17%)
   â”‚     â”‚  â””â”€ add_or_update_composedword (0.034s, 13%)
   â”‚     â”‚
   â”‚     â”œâ”€ get_tag (0.040s, 15%)
   â”‚     â”‚
   â”‚     â””â”€ _update_cooccurrence (0.023s, 9%)
   â”‚
   â””â”€ tokenize_sentences (0.063s, 24%)
      â”œâ”€ _sentences (0.027s)
      â””â”€ web_tokenizer (0.024s)
```

---

## ğŸ’¡ OPORTUNIDADES DE OTIMIZAÃ‡ÃƒO

### 1. ğŸ¥‡ PRIORIDADE ALTA

#### ComposedWord.__init__ (17% do tempo)
- **Problema:** CriaÃ§Ã£o de objetos compostos Ã© cara
- **Onde:** `yake\data\composed_word.py:31`
- **SoluÃ§Ãµes possÃ­veis:**
  - Usar __slots__ para reduzir overhead de memÃ³ria
  - Lazy evaluation de propriedades
  - Pool de objetos reutilizÃ¡veis
  - Cache de composiÃ§Ãµes frequentes

#### get_tag (15% do tempo)
- **Problema:** 3600 chamadas para obter tags
- **Onde:** `yake\data\utils.py:95`
- **SoluÃ§Ãµes possÃ­veis:**
  - Cache de tags por palavra (memoization)
  - PrÃ©-computar tags comuns
  - Otimizar regex patterns

#### add_or_update_composedword (13% do tempo)
- **Problema:** AtualizaÃ§Ã£o de candidatos
- **Onde:** `yake\data\core.py:545`
- **SoluÃ§Ãµes possÃ­veis:**
  - Melhorar estrutura de dados de candidatos
  - Usar defaultdict ou Counter
  - Batch updates ao invÃ©s de individual

### 2. ğŸ¥ˆ PRIORIDADE MÃ‰DIA

#### tokenize_sentences (24% do tempo)
- **Problema:** TokenizaÃ§Ã£o com biblioteca externa (segtok)
- **Onde:** `yake\data\utils.py:64`
- **SoluÃ§Ãµes possÃ­veis:**
  - Considerar tokenizer mais rÃ¡pido (spaCy, stanza)
  - Cache de sentenÃ§as tokenizadas
  - TokenizaÃ§Ã£o preguiÃ§osa (lazy)

#### _update_cooccurrence (9% do tempo)
- **Problema:** AtualizaÃ§Ãµes frequentes no grafo
- **Onde:** `yake\data\core.py:298`
- **SoluÃ§Ãµes possÃ­veis:**
  - Batch updates de cooccurrÃªncias
  - Estrutura de dados mais eficiente que networkx
  - Matriz de adjacÃªncia ao invÃ©s de grafo

### 3. ğŸ¥‰ PRIORIDADE BAIXA

#### String operations (join, lower, split)
- **Problema:** OperaÃ§Ãµes de string distribuÃ­das
- **Impacto:** ~5-10% total
- **SoluÃ§Ã£o:** Minimizar cÃ³pias de strings

---

## ğŸ”¬ PRÃ“XIMOS PASSOS RECOMENDADOS

### Fase 1: MediÃ§Ã£o Detalhada
```bash
# Instalar line_profiler e memory_profiler
pip install line-profiler memory-profiler

# Profiling linha-a-linha das funÃ§Ãµes crÃ­ticas
python -m line_profiler -l composed_word.py -l utils.py script.py

# Profiling de memÃ³ria
python -m memory_profiler script.py
```

### Fase 2: OtimizaÃ§Ãµes Incrementais

1. **Adicionar __slots__ a ComposedWord**
   ```python
   class ComposedWord:
       __slots__ = ['terms', 'surface_forms', 'tf', ...]
   ```

2. **Cache de tags**
   ```python
   from functools import lru_cache
   
   @lru_cache(maxsize=10000)
   def get_tag(word):
       ...
   ```

3. **Otimizar estrutura de candidatos**
   ```python
   # Usar defaultdict ao invÃ©s de dict manual
   from collections import defaultdict
   candidates = defaultdict(ComposedWord)
   ```

### Fase 3: ValidaÃ§Ã£o

Executar novamente este script e comparar:
```bash
python comprehensive_profiling.py
```

---

## ğŸ“ˆ EXPECTATIVAS REALISTAS

Com base nos hotspots identificados:

- **OtimizaÃ§Ã£o de ComposedWord:** 10-20% ganho
- **Cache de tags:** 10-15% ganho  
- **OtimizaÃ§Ã£o de estruturas de dados:** 5-10% ganho
- **Total esperado:** 25-45% melhoria

âš ï¸ **Nota:** TokenizaÃ§Ã£o (24%) Ã© externa (segtok) - difÃ­cil otimizar sem trocar biblioteca

---

## ğŸ¯ FOCO ESPECÃFICO: Valores Negativos

**QuestÃ£o:** O PR #96 Ã© workaround ou soluÃ§Ã£o apropriada?

### AnÃ¡lise do Profiling:
- `update_h()` em `single_word.py:233` aparece com apenas **0.004s (1.5%)**
- **NÃ£o Ã© um hotspot!**

### ConclusÃ£o:
âœ… O PR #96 Ã© uma **soluÃ§Ã£o apropriada**, nÃ£o workaround porque:

1. **Matematicamente correto:** Agrupa stopwords consecutivas
2. **Baixo impacto na performance:** <2% do tempo total
3. **Elimina completamente o bug:** 148 casos â†’ 0 casos
4. **NÃ£o adiciona complexidade significativa**

O problema dos valores negativos era um **bug matemÃ¡tico**, nÃ£o um problema de performance.
A correÃ§Ã£o Ã© elegante e nÃ£o impacta a velocidade do algoritmo.

---

## ğŸ“ ARQUIVO GERADO

Este resumo foi gerado automaticamente a partir do profiling em:
- Data: 2025-10-14 17:25:35
- RelatÃ³rio completo: `profiling_report_20251014_172535.txt`
- HTML interativo: `profile_pyinstrument_20251014_172535.html`

Para visualizar o HTML interativo:
1. Navegue atÃ© a pasta do projeto
2. Abra `profile_pyinstrument_20251014_172535.html` no navegador
3. Explore a Ã¡rvore de chamadas interativa

