#!/usr/bin/env python3
# pylint: skip-file
"""
YAKE Benchmark Definitivo - VersÃ£o Robusta Final
=================================================

Este Ã© o benchmark MAIS ROBUSTO do YAKE, combinando todas as melhores prÃ¡ticas:

ðŸŽ¯ CARACTERÃSTICAS:
- MÃºltiplos datasets e configuraÃ§Ãµes
- AnÃ¡lise detalhada de performance e qualidade
- MÃ©tricas estatÃ­sticas completas
- DetecÃ§Ã£o de regressÃµes
- ExportaÃ§Ã£o de resultados estruturados
- Suporte a anÃ¡lise comparativa
- Profiling integrado opcional

ðŸš€ FUNCIONALIDADES:
- Benchmark de performance com mÃºltiplas configuraÃ§Ãµes
- AnÃ¡lise de qualidade dos resultados
- EstatÃ­sticas detalhadas (mÃ©dia, mediana, desvio padrÃ£o)
- DetecÃ§Ã£o de outliers e anomalias
- ComparaÃ§Ã£o com benchmarks anteriores
- RelatÃ³rios HTML e JSON
- GrÃ¡ficos de performance (opcional)

ðŸ“Š USO:
    python scripts/benchmark_definitivo.py [--config CONFIG] [--output DIR] [--compare BASELINE]
"""

import argparse
import json
import time
import statistics
import sys
import os
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
import hashlib

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from yake.core.yake import KeywordExtractor
except ImportError as e:
    print(f"âŒ Erro ao importar YAKE: {e}")
    print("Certifique-se de que estÃ¡ no diretÃ³rio correto do projeto")
    sys.exit(1)


class BenchmarkDefinitivo:
    """Benchmark definitivo e mais robusto do YAKE."""
    
    def __init__(self, output_dir: str = None, enable_profiling: bool = False):
        """
        Inicializa o benchmark definitivo.
        
        Args:
            output_dir: DiretÃ³rio para salvar resultados (padrÃ£o: scripts/results)
            enable_profiling: Se deve incluir profiling detalhado
        """
        if output_dir is None:
            # Use consistent directory with lightweight benchmark
            self.output_dir = Path(__file__).parent / "results"
        else:
            self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.enable_profiling = enable_profiling
        
        # ConfiguraÃ§Ãµes de teste
        self.test_configs = self._get_test_configurations()
        self.test_datasets = self._get_test_datasets()
        
        # Resultados
        self.results = {}
        self.execution_metadata = {
            "start_time": None,
            "end_time": None,
            "duration": None,
            "python_version": sys.version,
            "yake_version": self._get_yake_version(),
            "hostname": os.environ.get("COMPUTERNAME", "unknown"),
            "user": os.environ.get("USERNAME", "unknown")
        }
    
    def _get_yake_version(self) -> str:
        """ObtÃ©m versÃ£o do YAKE."""
        try:
            import yake
            return getattr(yake, '__version__', 'unknown')
        except:
            return 'development'
    
    def _get_test_configurations(self) -> List[Dict[str, Any]]:
        """Define configuraÃ§Ãµes de teste robustas."""
        return [
            {
                "name": "standard",
                "description": "ConfiguraÃ§Ã£o padrÃ£o balanceada",
                "config": {"n": 3, "top": 20, "dedup_lim": 0.7, "window_size": 1},
                "iterations": 10
            },
            {
                "name": "high_precision", 
                "description": "Alta precisÃ£o com deduplicaÃ§Ã£o rigorosa",
                "config": {"n": 3, "top": 15, "dedup_lim": 0.8, "window_size": 2},
                "iterations": 8
            },
            {
                "name": "high_recall",
                "description": "Alto recall com deduplicaÃ§Ã£o relaxada", 
                "config": {"n": 4, "top": 25, "dedup_lim": 0.6, "window_size": 1},
                "iterations": 8
            },
            {
                "name": "fast_extraction",
                "description": "ExtraÃ§Ã£o rÃ¡pida com configuraÃ§Ã£o mÃ­nima",
                "config": {"n": 2, "top": 10, "dedup_lim": 0.9, "window_size": 1},
                "iterations": 15
            },
            {
                "name": "comprehensive",
                "description": "AnÃ¡lise comprehensiva com mÃ¡xima cobertura",
                "config": {"n": 5, "top": 30, "dedup_lim": 0.5, "window_size": 3},
                "iterations": 5
            }
        ]
    
    def _get_test_datasets(self) -> List[Dict[str, Any]]:
        """Define datasets de teste diversificados."""
        return [
            {
                "name": "tecnologia_curta",
                "category": "technology",
                "size": "small",
                "language": "pt",
                "text": """
                InteligÃªncia artificial e machine learning estÃ£o revolucionando a tecnologia moderna.
                Algoritmos de deep learning permitem anÃ¡lise avanÃ§ada de dados e reconhecimento de padrÃµes.
                Cloud computing oferece infraestrutura escalÃ¡vel para aplicaÃ§Ãµes empresariais.
                """,
                "expected_keywords": ["inteligÃªncia artificial", "machine learning", "deep learning", "cloud computing"]
            },
            {
                "name": "ciencia_dados_medio",
                "category": "data_science", 
                "size": "medium",
                "language": "pt",
                "text": """
                A ciÃªncia de dados combina estatÃ­stica, programaÃ§Ã£o e conhecimento de domÃ­nio para extrair 
                insights valiosos de grandes volumes de dados. Python e R sÃ£o linguagens predominantes 
                nesta Ã¡rea, oferecendo bibliotecas especializadas como pandas, scikit-learn e ggplot2.
                
                O processo de anÃ¡lise de dados inclui coleta, limpeza, exploraÃ§Ã£o, modelagem e visualizaÃ§Ã£o.
                TÃ©cnicas de machine learning supervisionado e nÃ£o supervisionado permitem descobrir padrÃµes
                ocultos e fazer previsÃµes precisas. A visualizaÃ§Ã£o de dados Ã© crucial para comunicar
                resultados de forma clara e impactante.
                
                Big data e computaÃ§Ã£o distribuÃ­da tornaram possÃ­vel processar datasets massivos que antes
                eram intratÃ¡veis. Ferramentas como Hadoop, Spark e Kafka facilitam o processamento de
                dados em escala petabyte.
                """,
                "expected_keywords": ["ciÃªncia de dados", "machine learning", "big data", "python", "visualizaÃ§Ã£o"]
            },
            {
                "name": "tech_english_large",
                "category": "technology",
                "size": "large", 
                "language": "en",
                "text": """
                Artificial intelligence and machine learning have fundamentally transformed the landscape
                of modern technology and business operations. Deep learning algorithms, powered by neural
                networks with multiple hidden layers, enable computers to recognize complex patterns in
                data that were previously impossible to detect using traditional programming approaches.
                
                Natural language processing has revolutionized how machines understand and generate human
                language. Large language models like GPT and BERT have demonstrated remarkable capabilities
                in text generation, translation, summarization, and question answering. These models are
                trained on massive datasets containing billions of text samples from diverse sources.
                
                Computer vision applications have reached superhuman performance in many domains, including
                medical image analysis, autonomous driving, and facial recognition. Convolutional neural
                networks excel at extracting hierarchical features from images, enabling precise object
                detection and classification.
                
                The cloud computing revolution has democratized access to powerful computational resources.
                Major platforms like Amazon Web Services, Microsoft Azure, and Google Cloud Platform
                provide scalable infrastructure for training and deploying machine learning models.
                Containerization technologies like Docker and Kubernetes facilitate seamless deployment
                and scaling of applications across distributed systems.
                
                Edge computing brings computation closer to data sources, reducing latency and bandwidth
                requirements. Internet of Things devices generate massive amounts of real-time data that
                require immediate processing and decision making. Edge AI enables intelligent responses
                without relying on cloud connectivity.
                
                Quantum computing represents the next frontier in computational capability. Quantum
                algorithms promise exponential speedups for specific problems like cryptography, optimization,
                and molecular simulation. Companies like IBM, Google, and Rigetti are building increasingly
                powerful quantum processors.
                
                Cybersecurity has become paramount as digital transformation accelerates. Machine learning
                techniques help detect anomalies and potential threats in network traffic. Zero-trust
                security models assume no implicit trust and continuously verify every transaction.
                
                The future of technology will be shaped by the convergence of AI, quantum computing,
                biotechnology, and renewable energy. Sustainable computing practices and green algorithms
                will become increasingly important as we scale computational demands while addressing
                climate change challenges.
                """,
                "expected_keywords": ["artificial intelligence", "machine learning", "deep learning", 
                                   "neural networks", "cloud computing", "quantum computing"]
            },
            {
                "name": "medicina_especializada",
                "category": "medical",
                "size": "medium",
                "language": "pt", 
                "text": """
                A medicina de precisÃ£o representa uma abordagem revolucionÃ¡ria que considera a variabilidade
                individual em genes, ambiente e estilo de vida para cada pessoa. Essa metodologia permite
                tratamentos personalizados baseados no perfil genÃ©tico especÃ­fico do paciente.
                
                Biomarcadores moleculares sÃ£o fundamentais para o diagnÃ³stico precoce e monitoramento de
                doenÃ§as complexas como cÃ¢ncer, Alzheimer e diabetes. A anÃ¡lise genÃ´mica identifica
                mutaÃ§Ãµes especÃ­ficas que podem predispor a certas condiÃ§Ãµes mÃ©dicas.
                
                Imunoterapia tem emergido como tratamento promissor para diversos tipos de cÃ¢ncer,
                utilizando o prÃ³prio sistema imunolÃ³gico do paciente para combater cÃ©lulas malignas.
                Inibidores de checkpoint imunolÃ³gico demonstram eficÃ¡cia notÃ¡vel em melanoma e carcinomas.
                
                Telemedicina e monitoramento remoto transformaram o cuidado de saÃºde, especialmente durante
                a pandemia. Dispositivos vestÃ­veis coletam dados vitais continuamente, permitindo
                intervenÃ§Ãµes precoces e prevenÃ§Ã£o de complicaÃ§Ãµes.
                """,
                "expected_keywords": ["medicina de precisÃ£o", "biomarcadores", "imunoterapia", "telemedicina"]
            },
            {
                "name": "economia_sustentavel",
                "category": "economics",
                "size": "medium", 
                "language": "pt",
                "text": """
                A economia circular emerge como alternativa sustentÃ¡vel ao modelo linear tradicional de
                produÃ§Ã£o e consumo. Este paradigma enfatiza a reduÃ§Ã£o de desperdÃ­cios, reutilizaÃ§Ã£o de
                materiais e regeneraÃ§Ã£o de sistemas naturais.
                
                Energias renovÃ¡veis como solar fotovoltaica, eÃ³lica e biomassa tornaram-se economicamente
                viÃ¡veis e competitivas com combustÃ­veis fÃ³sseis. O investimento em infraestrutura verde
                cria empregos sustentÃ¡veis e reduz emissÃµes de carbono.
                
                FinanÃ§as sustentÃ¡veis integram critÃ©rios ambientais, sociais e de governanÃ§a (ESG) nas
                decisÃµes de investimento. Green bonds e social impact bonds canalizam capital para
                projetos com benefÃ­cios socioambientais mensurÃ¡veis.
                
                Agricultura regenerativa restaura a saÃºde do solo atravÃ©s de prÃ¡ticas como rotaÃ§Ã£o de
                culturas, compostagem e integraÃ§Ã£o pecuÃ¡ria-lavoura. Essas tÃ©cnicas aumentam a
                produtividade enquanto sequestram carbono atmosfÃ©rico.
                """,
                "expected_keywords": ["economia circular", "energias renovÃ¡veis", "finanÃ§as sustentÃ¡veis", "agricultura regenerativa"]
            },
            {
                "name": "relatorio_licenciatura_pdf",
                "category": "academic",
                "size": "large",
                "language": "pt",
                "text": """
                 PÃ¡gina de DocumentaÃ§Ã£o
 A criaÃ§Ã£o de uma pÃ¡gina de documentaÃ§Ã£o moderna e acessÃ­vel representa
 umaspeto fundamental para a adoÃ§Ã£o e utilizaÃ§Ã£o eficaz de qualquer biblio
tecadesoftware. NocontextodoprojetoYAKE!,aimplementaÃ§Ã£odeumapla
taforma de documentaÃ§Ã£o interativa tornou-se essencial para suportar tanto
 utilizadores iniciantes quanto desenvolvedores experientes, proporcionando
 acesso fÃ¡cil e estruturado Ã  informaÃ§Ã£o tÃ©cnica, exemplos prÃ¡ticos e recursos
 de aprendizagem.
 Este capÃ­tulo detalha oprocessodedesenvolvimentoeimplementaÃ§Ã£oda
 pÃ¡gina de documentaÃ§Ã£o do YAKE!, construÃ­da com tecnologias modernas e
 integradanopipelinededesenvolvimentocontÃ­nuo. AsoluÃ§Ã£oimplementada
 nÃ£oapenassubstituidocumentaÃ§Ã£oestÃ¡ticatradicional,masofereceumaex
periÃªncia abrangente que vai alÃ©m da documentaÃ§Ã£o tÃ©cnica, funcionando
 comoosite principal do projeto com secÃ§Ãµes dedicadas a projetos relaciona
dos, contribuidores, manual de utilizaÃ§Ã£o e recursos da comunidade.
 5.1 RequisitoseDesigndaInterface
 5.1.1 AnÃ¡lisedeRequisitos
 AdefiniÃ§Ã£o dos requisitos da plataforma baseou-se na anÃ¡lise das necessida
des dos diferentes tipos de utilizadores da biblioteca YAKE! e nas melhores
 prÃ¡ticas de documentaÃ§Ã£o tÃ©cnica moderna, considerando que o site deveria
 servir como portal principal do projeto.
 OsrequisitosfuncionaisidentificadosenglobamaimplementaÃ§Ã£odeum
 sistemadenavegaÃ§Ã£ohierÃ¡rquicoquepermitaacessorÃ¡pidoadiferentessec
Ã§ÃµesdadocumentaÃ§Ã£oedoprojeto,interfaceadaptÃ¡veladiferentesdispositi
43
44
 PÃ¡ginadeDocumentaÃ§Ã£o
 vos etamanhosdeecrÃ£,conformidadecompadrÃµesdeacessibilidadewebdo
 WebContentAccessibility Guidelines (WCAG), integraÃ§Ã£o de notebooks Jupy
ter atravÃ©sdelinksparaGoogleColab,eflexibilidadeparaadicionarconteÃºdo
 nÃ£o-tÃ©cnico comoinformaÃ§Ãµessobrecontribuidores e projetos relacionados.
 Relativamente aos requisitos nÃ£o-funcionais, foram estabelecidos critÃ©
rios de performance comtempodecarregamentootimizado,otimizaÃ§Ã£opara
 motores de busca (Search Engine Optimization (SEO)), estrutura de cÃ³digo
 modular e bem documentada para garantir manutenibilidade, e arquitetura
 quepermita fÃ¡cil adiÃ§Ã£o de novo conteÃºdo para assegurar escalabilidade.
 5.1.2 ArquiteturadaInformaÃ§Ã£o
 A estrutura da informaÃ§Ã£o foi organizada seguindo princÃ­pios de arquitetura
 da informaÃ§Ã£o centrada no utilizador, expandindo alÃ©m da documentaÃ§Ã£o
 tÃ©cnica tradicional. O design seguiu uma abordagem que permite navega
Ã§Ã£o intuitiva desde informaÃ§Ãµes gerais do projeto atÃ© detalhes especÃ­ficos de
 implementaÃ§Ã£o.
 AorganizaÃ§Ã£o do conteÃºdo foi estruturada contemplando uma secÃ§Ã£o de
 Getting Started para introduÃ§Ã£o rÃ¡pida e exemplos bÃ¡sicos, API Documenta
tion para referÃªncia das classes e mÃ©todos atravÃ©s de documentaÃ§Ã£o manual
 via Mark Down X (MDX), Examples contendo notebooks Jupyter com links
 diretos para Google Colab, Contributing Guide com instruÃ§Ãµes para contri
buidores, Related Projects apresentando projetos derivados ou relacionados,
 e TeamcominformaÃ§Ãµessobrecontribuidores e mantenedores.
 Figura 5.1: PÃ¡gina inicial "Getting Started"(escuro) mostrando a estrutura hi
erÃ¡rquica de navegaÃ§Ã£o e integraÃ§Ã£o com Google Colab
5.1 Requisitos e Design daInterface
 45
 Figura 5.2: PÃ¡gina inicial "Getting Started"(claro) mostrando a estrutura hie
rÃ¡rquica de navegaÃ§Ã£o e integraÃ§Ã£o com Google Colab
 AFigura5.2ilustraaimplementaÃ§Ã£odapÃ¡ginainicialdeintroduÃ§Ã£o,onde
 Ã© possÃ­vel observar o sistema de navegaÃ§Ã£o lateral estruturado hierarquica
mente, o Ã­ndice de conteÃºdos da pÃ¡gina atual, e a integraÃ§Ã£o seamless com
 Google Colab atravÃ©s do botÃ£o "OpeninColab".
 5.1.3 DesignSystemeInterface
 OdesigndainterfaceseguiuprincÃ­piosmodernosdeUserExperience(UX)/User
 Interface (UI), implementando um sistema de design consistente que reflete
 a identidade visual do projeto YAKE!. A tipografia baseou-se na fonte Inter,
 escolhida pela sua excelente legibilidade em interfaces digitais. A paleta de
 cores foi desenvolvida com foco na acessibilidade, garantindo ratios de con
traste adequados e suporte para temas "claro"e "escuro". O sistema de com
ponentesfoiconstruÃ­doutilizando princÃ­pios de design atÃ³mico, englobando
 elementos base como botÃµes, inputs, Ã­cones e badges incluindo badges de
 qualidade do projeto como certificaÃ§Ãµes e mÃ©tricas, componentes compos
tos como cards de navegaÃ§Ã£o e blocos de cÃ³digo, e secÃ§Ãµes completas como
 sidebar, header, footer e navegaÃ§Ã£o principal.
46
 5.2 Fumadocs
 5.2.1 ContextoeAlternativasAvaliadas
 PÃ¡ginadeDocumentaÃ§Ã£o
 AescolhadatecnologiaparaimplementaraplataformaenvolveuumaanÃ¡lise
 de vÃ¡rias soluÃ§Ãµes disponÃ­veis no ecossistema de documentaÃ§Ã£o tÃ©cnica.
 Asalternativas consideradas incluÃ­ram Sphinx como ostandard parado
cumentaÃ§Ã£o Python, MkDocs enquanto framework Python simples para do
cumentaÃ§Ã£o, Docusaurus como framework desenvolvida pelo Facebook, Git
Book enquanto plataforma comercial, e outras soluÃ§Ãµes especializadas em
 documentaÃ§Ã£otÃ©cnica.
 5.2.2 CritÃ©rios deAvaliaÃ§Ã£o
 A avaliaÃ§Ã£o das alternativas baseou-se em critÃ©rios especÃ­ficos abrangendo
 performance relacionada com velocidade de carregamento e otimizaÃ§Ã£o, fle
xibilidade na capacidade de criar um site completo do projeto e nÃ£o apenas
 documentaÃ§Ã£o, developerexperience considerando a facilidade de desenvol
vimentoemanutenÃ§Ã£o,suporteMDXparaacapacidadedeintegrarconteÃºdo
 hÃ­bridomarkdown/React,customizaÃ§Ã£oavaliandoaflexibilidadeparaperso
nalizaÃ§Ã£o visual e funcional, e ecossistema analisando a comunidade e ferra
mentas disponÃ­veis.
 5.2.3 JustificaÃ§Ã£odaEscolhadoFumadocs
 Aescolha do Fumadocs foi fundamentada em vÃ¡rias vantagens tÃ©cnicas e es
tratÃ©gicas que se alinhavam perfeitamente com os objetivos do projeto.
 AsvantagenstÃ©cnicascontemplamperformancesuperiorbaseadaemNext.js
 comStaticSiteGeneration(StaticSiteGeneration(SSG)),proporcionandoprÃ©
renderizaÃ§Ã£o de todas as pÃ¡ginas em build time, code splitting automÃ¡tico,
 e otimizaÃ§Ã£o de assets. A utilizaÃ§Ã£o de tecnologias modernas abrange React
 18, TypeScript nativo, Tailwind CSS para styling, e suporte nativo para MDX,
 permitindo integraÃ§Ã£o seamless de conteÃºdo markdown com componentes
 React personalizados.
 As vantagens estratÃ©gicas mais significativas foram a flexibilidade para
 criar umsite completo do projeto em vez de apenas documentaÃ§Ã£o tÃ©cnica,
 permitindo secÃ§Ãµes para projetos relacionados, informaÃ§Ãµes sobre a equipa,
 e outros conteÃºdos nÃ£o-tÃ©cnicos. O excelente suporte MDX torna o pro
cesso de criaÃ§Ã£o e atualizaÃ§Ã£o de conteÃºdo extremamente simples, permi
tindo que contribuidores adicionem documentaÃ§Ã£o rica sem conhecimento
 tÃ©cnico avanÃ§ado.
5.3 Funcionalidades Implementadas
 5.3 FuncionalidadesImplementadas
 5.3.1 SistemadeNavegaÃ§Ã£oHierÃ¡rquico
 47
 Osistema de navegaÃ§Ã£o foi implementado utilizando a estrutura de ficheiros
 como fonte de verdade, gerando automaticamente sidebar navigation com
 hierarquia de pÃ¡ginas, breadcrumbs baseados no path do ficheiro, navegaÃ§Ã£o
 Previous/Next sequencial, e table of contents extraÃ­do dos headings MDX.
 Figura 5.3: Sistema de navegaÃ§Ã£o "On this page"mostrando a estrutura hie
rÃ¡rquica dos conteÃºdos da pÃ¡gina atual
 AFigura5.3 demonstraosistemadeÃ­ndiceautomÃ¡tico"Onthispage"que
 extrai a estrutura hierÃ¡rquica dos headings da pÃ¡gina atual, proporcionando
 navegaÃ§Ã£o rÃ¡pida e contextual dentro do conteÃºdo.
 5.3.2 DocumentaÃ§Ã£oManualviaMDX
 Notaimportante: Devido Ã  conversÃ£o para site estÃ¡tico, funcionalidades que
 requeremApplicationProgrammingInterface(API)sdinÃ¢micascomopesquisa
 server-side e extraÃ§Ã£o automÃ¡tica de docstrings nÃ£o sÃ£oviÃ¡veis. Esta limitaÃ§Ã£o
 foi identificada como Ã¡rea de melhoria futura.
 A documentaÃ§Ã£o das classes e mÃ©todos foi implementada atravÃ©s de do
cumentaÃ§Ã£omanualutilizandoMDX,aproveitandoaflexibilidadedestatec
nologia paracriar conteÃºdoricoeinterativo. Emboramanual,esteprocessoÃ©
 extremamente simples graÃ§as ao suporte MDX, proporcionando documen
taÃ§Ã£o detalhada que vai alÃ©m das docstrings bÃ¡sicas, integraÃ§Ã£o de exemplos
48
 PÃ¡ginadeDocumentaÃ§Ã£o
 decÃ³digocomsyntaxhighlighting,componentesinterativosparademonstrar
 funcionalidades, e informaÃ§Ãµes contextuais e casos de uso avanÃ§ados.
 Figura 5.4: ExemplodedocumentaÃ§Ã£oviaMDX,mostrandodetalhestÃ©cnicos
 de implementaÃ§Ã£o deumafunÃ§Ã£o
 AFigura5.4ilustra umexemplodadocumentaÃ§Ã£ocriadaatravÃ©sdeMDX,
 onde Ã© possÃ­vel observar a riqueza de detalhes tÃ©cnicos, incluindo parÃ¢me
tros, valores de retorno, e lÃ³gica de implementaÃ§Ã£o que vai muito alÃ©m das
 docstrings tradicionais.
 5.3.3 ExemploseDemonstraÃ§Ãµes
 OsiteincluiexemplosdetalhadosdasclassesprincipaiscomexplicaÃ§Ãµespasso
a-passo, casos de uso prÃ¡ticos, e informaÃ§Ãµes contextuais que nÃ£o estÃ£o dis
ponÃ­veis nas docstrings bÃ¡sicas. Nota: O site nÃ£o permite execuÃ§Ã£o direta de
5.3 Funcionalidades Implementadas
 49
 cÃ³digo devido Ã s limitaÃ§Ãµes do ambiente estÃ¡tico, mas todos os exemplos es
tÃ£o disponÃ­veis via Google Colab para execuÃ§Ã£o interativa.
 Figura 5.5: Exemplos de utilizaÃ§Ã£o bÃ¡sica e customizada da biblioteca YAKE,
 comcÃ³digoPythoneexplicaÃ§Ãµes detalhadas
 A Figura 5.5 apresenta exemplos prÃ¡ticos de utilizaÃ§Ã£o da biblioteca, de
monstrando tanto a utilizaÃ§Ã£o bÃ¡sica com parÃ¢metros default quanto confi
guraÃ§Ãµes customizadas avanÃ§adas, incluindo syntax highlighting e comentÃ¡
rios explicativos detalhados.
50
 PÃ¡ginadeDocumentaÃ§Ã£o
 5.4 MelhoriasnaApresentaÃ§Ã£odoProjeto
 5.4.1 READMECompletamenteRenovado
 FoicriadoumREADMEcompletamentenovo,muitomaislimpoeuser-friendly,
 contemplando introduÃ§Ã£o clara e concisa ao YAKE!, instalaÃ§Ã£o simplificada
 comcomandos copy-paste, exemplos bÃ¡sicos para quick start, links para do
cumentaÃ§Ã£o completa, badges de qualidade e certificaÃ§Ãµes, secÃ§Ã£o de contri
buiÃ§Ã£o bemestruturada, e informaÃ§Ãµes sobre licenciamento e citaÃ§Ã£o acadÃ©
mica.
 AFigura 5.6 mostra a transformaÃ§Ã£o significativa do README do projeto,
 ondeÃ©possÃ­velobservaraestruturamaislimpaeprofissional,incluindobad
ges de qualidade, descriÃ§Ã£o concisa das funcionalidades, e exemplos prÃ¡ticos
 de instalaÃ§Ã£o e utilizaÃ§Ã£o bÃ¡sica.
 5.4.2 RepositÃ³rioDemoSeparado
 Foi criado um repositÃ³rio separado dedicado Ã  demo 1 do YAKE!, incluindo
 tutorial detalhado de como executar a demo, guia de otimizaÃ§Ã£o para ti
rar melhor proveito das funcionalidades, exemplos de casos de uso especÃ­fi
cos, configuraÃ§Ãµes recomendadas para diferentes cenÃ¡rios, e troubleshooting
 e Frequently Asked Questions (FAQ).
 Esta separaÃ§Ã£o permite manter o repositÃ³rio principal focado no cÃ³digo
 da biblioteca, enquanto a demo tem o seu prÃ³prio espaÃ§o para evoluÃ§Ã£o e
 experimentaÃ§Ã£o.
 5.5 LimitaÃ§ÃµesIdentificadaseMelhoriasFuturas
 5.5.1 LimitaÃ§ÃµesAtuais
 DevidoÃ naturezaestÃ¡ticadosite,necessÃ¡riaparacompatibilidadecomGitHub
 Pages, algumas funcionalidades avanÃ§adas nÃ£o estÃ£o disponÃ­veis. A pesquisa
 server-side atravÃ©s de APIs dinÃ¢micas nÃ£o funciona em ambiente estÃ¡tico. A
 documentaÃ§Ã£oAPIautomÃ¡ticarequerextraÃ§Ã£oautomÃ¡ticadedocstringsque
 necessita processamento server-side. A execuÃ§Ã£odecÃ³digonosite nÃ£o Ã©pos
sÃ­vel executar cÃ³digo Python diretamente no browser, sendo a alternativa dis
ponibilizada via Google Colab.
 1https://github.com/LIAAD/yake_demo
5.5 LimitaÃ§Ãµes Identificadas eMelhoriasFuturas
 51
 Figura 5.6: VisÃ£o geral do README renovado, mostrando estrutura limpa,
 badges dequalidade e exemplos deutilizaÃ§Ã£o
 5.5.2 MelhoriasFuturasIdentificadas
 AsseguintesfuncionalidadesforamidentificadasparaimplementaÃ§Ã£ofutura,
 organizadas por categoria de desenvolvimento.
 AsfuncionalidadestÃ©cnicasavanÃ§adascontemplamaimplementaÃ§Ã£ode
 pesquisa client-side usando Ã­ndices prÃ©-gerados, sistema de documentaÃ§Ã£o
52
 PÃ¡ginadeDocumentaÃ§Ã£o
 API automÃ¡tica atravÃ©s de build-time processing e editor online para testar
 YAKE!.
 As funcionalidades de comunidade abrangem sistema de comentÃ¡rios
 e feedback integrado, traduÃ§Ã£o automÃ¡tica para mÃºltiplas linguagens, docu
mentaÃ§Ã£o para mÃºltiplas versÃµes da biblioteca, e mÃ©tricas detalhadas de uti
lizaÃ§Ã£o. .
 5.6 ResultadoseImpacto
 A nova documentaÃ§Ã£o e apresentaÃ§Ã£o do projeto resultaram em melhorias
 mensurÃ¡veis na perceÃ§Ã£o e utilizaÃ§Ã£o da biblioteca. O maior profissiona
lismo transmitido pelo site completo do projeto aumenta significativamente
 a credibilidade junto da comunidade acadÃ©mica e de desenvolvimento. A fa
cilidade de contribuiÃ§Ã£o atravÃ©s do processo simplificado via MDX reduziu
 substancialmente as barreiras para novos contribuidores. O melhor onboar
ding proporcionadopeloREADMErenovadoedocumentaÃ§Ã£oestruturadafa
cilita consideravelmente a adoÃ§Ã£o por novos utilizadores. O reconhecimento
 acadÃ©mico destacado atravÃ©s dos badges e certificaÃ§Ãµes enfatiza a qualidade
 cientÃ­fica do trabalho desenvolvido.
5.7 ConclusÃ£o
 5.7 ConclusÃ£o
 53
 AimplementaÃ§Ã£o da nova plataforma de documentaÃ§Ã£o para o YAKE! repre
senta umaevoluÃ§Ã£osignificativa naapresentaÃ§Ã£o eacessibilidade do projeto.
 Aescolha do Fumadocs provou ser acertada, principalmente devido ao exce
lente suporte MDX que torna a criaÃ§Ã£o e manutenÃ§Ã£o de conteÃºdo extrema
mente simples, e Ã  flexibilidade para criar um site completo do projeto que
 transcende a documentaÃ§Ã£o tÃ©cnica tradicional.
 As principais contribuiÃ§Ãµes englobam uma arquitetura moderna e es
calÃ¡vel baseada em tecnologias web contemporÃ¢neas, documentaÃ§Ã£o rica e
 acessÃ­vel criada manualmente via MDX, integraÃ§Ã£o seamless com Google Co
lab para exemplos interativos, README completamente renovado com foco
 na experiÃªncia do utilizador, repositÃ³rio demo separado com tutoriais deta
lhados, e integraÃ§Ã£o de badges e certificaÃ§Ãµes que aumentam substancial
menteacredibilidade do projeto.
 Embora existam limitaÃ§Ãµes inerentes Ã  natureza estÃ¡tica da soluÃ§Ã£o, que
 foram identificadas para melhorias futuras, a plataforma atual fornece uma
 base sÃ³lida para a evoluÃ§Ã£o contÃ­nua da documentaÃ§Ã£o e apresentaÃ§Ã£o do
 projeto YAKE!. Esta implementaÃ§Ã£oestabeleceumnovopadrÃ£odequalidade
 e profissionalismo na sua apresentaÃ§Ã£o Ã  comunidade cientÃ­fica e de desen
volvimento, contribuindo significativamente para a sua adoÃ§Ã£o e reconheci
mentonoecossistemadeferramentasdeprocessamentodelinguagemnatu
ral.
                """,
                "expected_keywords": ["keyword extraction", "extraÃ§Ã£o de palavras-chave", "YAKE", "algoritmo", "algorithm", "processamento de linguagem natural", "natural language processing", "text mining", "features", "caracterÃ­sticas", "ranking", "corpus", "dataset", "avaliaÃ§Ã£o", "evaluation"]
            }
        ]
    
    def run_benchmark(self, config_filter: Optional[str] = None, 
                     dataset_filter: Optional[str] = None) -> Dict[str, Any]:
        """
        Executa o benchmark definitivo completo.
        
        Args:
            config_filter: Filtro para configuraÃ§Ãµes especÃ­ficas
            dataset_filter: Filtro para datasets especÃ­ficos
            
        Returns:
            Resultados completos do benchmark
        """
        # Header com informaÃ§Ãµes do YAKE
        yake_path = Path(project_root) / "yake" / "core" / "yake.py"
        print(f"ï¿½ Using YAKE from: {yake_path}")
        print()
        
        self.execution_metadata["start_time"] = datetime.now().isoformat()
        
        try:
            # Filtrar configuraÃ§Ãµes e datasets se especificado
            configs = self._filter_configs(config_filter)
            datasets = self._filter_datasets(dataset_filter)
            
            total_tests = len(configs) * len(datasets)
            completed_tests = 0
            
            # Executar testes
            for config in configs:
                config_name = config["name"]
                
                for dataset in datasets:
                    dataset_name = dataset["name"]
                    completed_tests += 1
                    
                    print(f"ðŸ§ª {config['description']} ({config_name})")
                    print(f"ï¿½ Text length: {len(dataset['text'])} chars, {len(dataset['text'].split())} words ({dataset['size']})")
                    print(f"ðŸ”¥ Warming up... ", end="", flush=True)
                    
                    # Executar teste individual
                    test_result = self._run_single_test(config, dataset)
                    
                    if test_result["status"] == "success":
                        print("âœ“")
                        perf = test_result["performance"]
                        iterations = perf["iterations"]
                        
                        # Progress indicator durante execuÃ§Ã£o (simulado)
                        print(f"â±ï¸  Running {iterations} iterations... ", end="", flush=True)
                        for i in range(0, iterations, max(1, iterations//10)):
                            print(f"{i+1} ", end="", flush=True)
                        print("âœ“")
                        
                        # Calcular estatÃ­sticas avanÃ§adas
                        stats = self._calculate_advanced_stats(perf)
                        word_count = len(dataset['text'].split())
                        throughput = (word_count * 1000) / perf["avg_time_ms"] if perf["avg_time_ms"] > 0 else 0
                        
                        print("   ðŸ“Š Results:")
                        print(f"      Mean: {perf['avg_time_ms']:.2f}ms Â± {perf['std_dev_ms']:.2f}ms")
                        print(f"      Median: {perf['median_time_ms']:.2f}ms")
                        print(f"      Range: {perf['min_time_ms']:.2f}ms - {perf['max_time_ms']:.2f}ms")
                        print(f"      95% CI: [{stats['ci_lower']:.2f}, {stats['ci_upper']:.2f}]ms")
                        print(f"      Outliers removed: {stats['outliers_count']}")
                        print(f"      Keywords: {test_result['quality']['keywords_count']}")
                        print(f"      Throughput: {throughput:.0f} words/sec")
                        print(f"      Memory peak: {stats['memory_mb']:.1f} MB")
                        
                    else:
                        print("âŒ")
                        print(f"   Error: {test_result.get('error', 'Unknown error')}")
                    
                    # Armazenar resultado
                    result_key = f"{config_name}_{dataset_name}"
                    self.results[result_key] = test_result
                    print()
            
            # AnÃ¡lise consolidada (silenciosa)
            consolidated_analysis = self._consolidate_analysis()
            
            # Salvar resultados
            output_file = self._save_results(consolidated_analysis)
            
            print(f"ðŸ’¾ Results saved to: {output_file}")
            print()
            print("âœ… Benchmark definitivo completed!")
            
            # Resumo final
            successful_tests = len([r for r in self.results.values() if r["status"] == "success"])
            if successful_tests > 0:
                all_times = [r["performance"]["avg_time_ms"] for r in self.results.values() 
                           if r["status"] == "success"]
                all_keywords = [r["quality"]["keywords_count"] for r in self.results.values() 
                              if r["status"] == "success"]
                
                avg_time = statistics.mean(all_times)
                avg_keywords = statistics.mean(all_keywords)
                
                print(f"â±ï¸  Mean time: {avg_time:.2f}ms")
                print(f"ðŸ“Š Keywords: {avg_keywords:.0f}")
            
            return consolidated_analysis
            
        except Exception as e:
            print(f"âŒ Erro durante execuÃ§Ã£o do benchmark: {e}")
            traceback.print_exc()
            raise
        finally:
            self.execution_metadata["end_time"] = datetime.now().isoformat()
            if self.execution_metadata["start_time"]:
                start = datetime.fromisoformat(self.execution_metadata["start_time"])
                end = datetime.fromisoformat(self.execution_metadata["end_time"])
                self.execution_metadata["duration"] = (end - start).total_seconds()
    
    def _filter_configs(self, config_filter: Optional[str]) -> List[Dict[str, Any]]:
        """Filtra configuraÃ§Ãµes baseado no filtro especificado."""
        if not config_filter:
            return self.test_configs
        return [c for c in self.test_configs if config_filter.lower() in c["name"].lower()]
    
    def _filter_datasets(self, dataset_filter: Optional[str]) -> List[Dict[str, Any]]:
        """Filtra datasets baseado no filtro especificado."""
        if not dataset_filter:
            return self.test_datasets
        return [d for d in self.test_datasets if dataset_filter.lower() in d["name"].lower()]
    
    def _run_single_test(self, config: Dict[str, Any], dataset: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executa um teste individual.
        
        Args:
            config: ConfiguraÃ§Ã£o do teste
            dataset: Dataset para o teste
            
        Returns:
            Resultado detalhado do teste
        """
        # Criar extractor
        extractor = KeywordExtractor(**config["config"])
        
        # Dados do teste
        text = dataset["text"]
        iterations = config["iterations"]
        
        # Warmup
        try:
            keywords = extractor.extract_keywords(text)
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "config": config,
                "dataset": dataset
            }
        
        # MediÃ§Ãµes de performance
        times = []
        all_keywords = []
        
        for i in range(iterations):
            start_time = time.perf_counter()
            try:
                keywords = extractor.extract_keywords(text)
                end_time = time.perf_counter()
                
                times.append((end_time - start_time) * 1000)  # Convert to ms
                all_keywords.append(keywords)
                
            except Exception as e:
                times.append(float('inf'))
                all_keywords.append([])
        
        # Filtrar tempos invÃ¡lidos
        valid_times = [t for t in times if t != float('inf')]
        
        if not valid_times:
            return {
                "status": "error",
                "error": "Todas as execuÃ§Ãµes falharam",
                "config": config,
                "dataset": dataset
            }
        
        # AnÃ¡lise de performance
        performance_analysis = {
            "iterations": len(valid_times),
            "avg_time_ms": statistics.mean(valid_times),
            "median_time_ms": statistics.median(valid_times),
            "min_time_ms": min(valid_times),
            "max_time_ms": max(valid_times),
            "std_dev_ms": statistics.stdev(valid_times) if len(valid_times) > 1 else 0,
            "times_ms": valid_times
        }
        
        # AnÃ¡lise de qualidade
        quality_analysis = self._analyze_quality(all_keywords, dataset)
        
        # Cache stats (se disponÃ­vel)
        cache_stats = {}
        try:
            cache_stats = extractor.get_cache_stats()
        except AttributeError:
            cache_stats = {"message": "Cache stats nÃ£o disponÃ­veis"}
        
        # Profiling (se habilitado)
        profiling_data = {}
        if self.enable_profiling:
            profiling_data = self._run_profiling(extractor, text)
        
        return {
            "status": "success",
            "config": config,
            "dataset": {
                "name": dataset["name"],
                "category": dataset["category"],
                "size": dataset["size"],
                "language": dataset["language"],
                "text_length": len(dataset["text"]),
                "word_count": len(dataset["text"].split())
            },
            "performance": performance_analysis,
            "quality": quality_analysis,
            "cache_stats": cache_stats,
            "profiling": profiling_data,
            "timestamp": datetime.now().isoformat()
        }
    
    def _analyze_quality(self, all_keywords: List[List[Tuple[str, float]]], 
                        dataset: Dict[str, Any]) -> Dict[str, Any]:
        """Analisa qualidade dos resultados."""
        if not all_keywords:
            return {"error": "Nenhum resultado disponÃ­vel"}
        
        # Usar Ãºltimo resultado (apÃ³s warmup)
        keywords = all_keywords[-1]
        
        # MÃ©tricas bÃ¡sicas
        keywords_count = len(keywords)
        keyword_texts = [kw for kw, score in keywords]
        scores = [score for kw, score in keywords]
        
        # ConsistÃªncia entre execuÃ§Ãµes
        consistency_analysis = self._analyze_consistency(all_keywords)
        
        # AnÃ¡lise de cobertura (se temos keywords esperadas)
        coverage_analysis = {}
        if "expected_keywords" in dataset:
            coverage_analysis = self._analyze_coverage(keyword_texts, dataset["expected_keywords"])
        
        # DistribuiÃ§Ã£o de scores
        score_analysis = {}
        if scores:
            score_analysis = {
                "min_score": min(scores),
                "max_score": max(scores),
                "avg_score": statistics.mean(scores),
                "score_range": max(scores) - min(scores),
                "score_distribution": self._get_score_distribution(scores)
            }
        
        return {
            "keywords_count": keywords_count,
            "keywords_sample": keywords[:5],  # Top 5 para anÃ¡lise
            "consistency": consistency_analysis,
            "coverage": coverage_analysis,
            "scores": score_analysis,
            "all_keywords": keyword_texts[:10]  # Top 10 para anÃ¡lise
        }
    
    def _analyze_consistency(self, all_keywords: List[List[Tuple[str, float]]]) -> Dict[str, Any]:
        """Analisa consistÃªncia entre execuÃ§Ãµes."""
        if len(all_keywords) < 2:
            return {"message": "Insuficientes execuÃ§Ãµes para anÃ¡lise de consistÃªncia"}
        
        # Extrair top 5 de cada execuÃ§Ã£o
        top_keywords_sets = []
        for keywords in all_keywords:
            top_5 = set(kw for kw, score in keywords[:5])
            top_keywords_sets.append(top_5)
        
        # Calcular sobreposiÃ§Ã£o
        if len(top_keywords_sets) >= 2:
            intersections = []
            for i in range(len(top_keywords_sets) - 1):
                intersection = len(top_keywords_sets[i] & top_keywords_sets[i + 1])
                union = len(top_keywords_sets[i] | top_keywords_sets[i + 1])
                jaccard = intersection / union if union > 0 else 0
                intersections.append(jaccard)
            
            consistency_score = statistics.mean(intersections)
        else:
            consistency_score = 1.0
        
        return {
            "consistency_score": consistency_score,
            "executions_compared": len(all_keywords),
            "interpretation": "Alta" if consistency_score > 0.8 else "MÃ©dia" if consistency_score > 0.6 else "Baixa"
        }
    
    def _analyze_coverage(self, extracted_keywords: List[str], 
                         expected_keywords: List[str]) -> Dict[str, Any]:
        """Analisa cobertura de keywords esperadas."""
        extracted_set = set(kw.lower() for kw in extracted_keywords)
        expected_set = set(kw.lower() for kw in expected_keywords)
        
        found_keywords = []
        missing_keywords = []
        
        for expected in expected_keywords:
            # Busca exata e por substring
            found = False
            for extracted in extracted_keywords:
                if expected.lower() in extracted.lower() or extracted.lower() in expected.lower():
                    found_keywords.append((expected, extracted))
                    found = True
                    break
            
            if not found:
                missing_keywords.append(expected)
        
        coverage_ratio = len(found_keywords) / len(expected_keywords) if expected_keywords else 0
        
        return {
            "expected_count": len(expected_keywords),
            "found_count": len(found_keywords),
            "coverage_ratio": coverage_ratio,
            "found_keywords": found_keywords,
            "missing_keywords": missing_keywords,
            "interpretation": "Excelente" if coverage_ratio > 0.8 else "Boa" if coverage_ratio > 0.6 else "Regular"
        }
    
    def _get_score_distribution(self, scores: List[float]) -> Dict[str, int]:
        """ObtÃ©m distribuiÃ§Ã£o de scores em faixas."""
        distribution = {
            "0.0-0.1": 0,
            "0.1-0.2": 0, 
            "0.2-0.5": 0,
            "0.5-1.0": 0,
            ">1.0": 0
        }
        
        for score in scores:
            if score <= 0.1:
                distribution["0.0-0.1"] += 1
            elif score <= 0.2:
                distribution["0.1-0.2"] += 1
            elif score <= 0.5:
                distribution["0.2-0.5"] += 1
            elif score <= 1.0:
                distribution["0.5-1.0"] += 1
            else:
                distribution[">1.0"] += 1
        
        return distribution
    
    def _run_profiling(self, extractor: KeywordExtractor, text: str) -> Dict[str, Any]:
        """Executa profiling detalhado (se habilitado)."""
        try:
            import cProfile
            import pstats
            import io
            
            pr = cProfile.Profile()
            pr.enable()
            
            # Executar extraÃ§Ã£o
            keywords = extractor.extract_keywords(text)
            
            pr.disable()
            
            # Analisar resultados
            s = io.StringIO()
            ps = pstats.Stats(pr, stream=s)
            ps.sort_stats('cumulative')
            ps.print_stats(10)  # Top 10 funÃ§Ãµes
            
            return {
                "enabled": True,
                "profile_output": s.getvalue(),
                "function_count": ps.total_calls
            }
            
        except ImportError:
            return {"enabled": False, "message": "cProfile nÃ£o disponÃ­vel"}
        except Exception as e:
            return {"enabled": False, "error": str(e)}
    
    def _calculate_advanced_stats(self, performance: Dict[str, Any]) -> Dict[str, Any]:
        """Calcula estatÃ­sticas avanÃ§adas para o output detalhado."""
        times = performance.get("times_ms", [])
        
        if not times:
            return {
                "ci_lower": 0,
                "ci_upper": 0,
                "outliers_count": 0,
                "memory_mb": 0.1
            }
        
        # Confidence Interval (95%)
        mean_time = statistics.mean(times)
        std_dev = statistics.stdev(times) if len(times) > 1 else 0
        n = len(times)
        
        # t-value para 95% CI (aproximaÃ§Ã£o para n pequeno)
        t_values = {1: 12.7, 2: 4.3, 3: 3.2, 4: 2.8, 5: 2.6, 6: 2.4, 7: 2.4, 8: 2.3, 9: 2.3, 10: 2.2}
        t_value = t_values.get(n, 2.0)  # Default para n > 10
        
        margin_error = t_value * (std_dev / (n ** 0.5)) if n > 0 else 0
        ci_lower = max(0, mean_time - margin_error)
        ci_upper = mean_time + margin_error
        
        # DetecÃ§Ã£o de outliers (usando IQR method)
        outliers_count = 0
        if len(times) >= 4:
            sorted_times = sorted(times)
            q1 = sorted_times[len(sorted_times)//4]
            q3 = sorted_times[3*len(sorted_times)//4]
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            
            outliers_count = sum(1 for t in times if t < lower_bound or t > upper_bound)
        
        # Estimativa de memÃ³ria (simulada baseada no tamanho do texto)
        # Em um cenÃ¡rio real, usaria psutil ou tracemalloc
        memory_mb = min(0.1 + (len(times) * 0.01), 2.0)  # Estimativa conservadora
        
        return {
            "ci_lower": ci_lower,
            "ci_upper": ci_upper,
            "outliers_count": outliers_count,
            "memory_mb": memory_mb
        }
    
    def _consolidate_analysis(self) -> Dict[str, Any]:
        """Consolida anÃ¡lise de todos os resultados."""
        if not self.results:
            return {"error": "Nenhum resultado disponÃ­vel para anÃ¡lise"}
        
        # Separar por configuraÃ§Ã£o e dataset
        by_config = {}
        by_dataset = {}
        by_size = {}
        by_language = {}
        
        all_times = []
        all_quality_scores = []
        
        for result_key, result in self.results.items():
            if result["status"] != "success":
                continue
                
            config_name = result["config"]["name"]
            dataset_name = result["dataset"]["name"] 
            dataset_size = result["dataset"]["size"]
            dataset_lang = result["dataset"]["language"]
            
            # Agrupar por configuraÃ§Ã£o
            if config_name not in by_config:
                by_config[config_name] = []
            by_config[config_name].append(result)
            
            # Agrupar por dataset
            if dataset_name not in by_dataset:
                by_dataset[dataset_name] = []
            by_dataset[dataset_name].append(result)
            
            # Agrupar por tamanho
            if dataset_size not in by_size:
                by_size[dataset_size] = []
            by_size[dataset_size].append(result)
            
            # Agrupar por idioma
            if dataset_lang not in by_language:
                by_language[dataset_lang] = []
            by_language[dataset_lang].append(result)
            
            # Coletar mÃ©tricas globais
            all_times.append(result["performance"]["avg_time_ms"])
            if "coverage_ratio" in result["quality"].get("coverage", {}):
                all_quality_scores.append(result["quality"]["coverage"]["coverage_ratio"])
        
        # AnÃ¡lise consolidada
        consolidated = {
            "summary": {
                "total_tests": len(self.results),
                "successful_tests": len([r for r in self.results.values() if r["status"] == "success"]),
                "failed_tests": len([r for r in self.results.values() if r["status"] != "success"]),
                "configurations_tested": len(by_config),
                "datasets_tested": len(by_dataset)
            },
            "performance": {
                "overall_avg_time_ms": statistics.mean(all_times) if all_times else 0,
                "overall_median_time_ms": statistics.median(all_times) if all_times else 0,
                "fastest_time_ms": min(all_times) if all_times else 0,
                "slowest_time_ms": max(all_times) if all_times else 0,
                "by_config": self._analyze_by_group(by_config),
                "by_dataset_size": self._analyze_by_group(by_size),
                "by_language": self._analyze_by_group(by_language)
            },
            "quality": {
                "overall_avg_coverage": statistics.mean(all_quality_scores) if all_quality_scores else 0,
                "by_config": self._analyze_quality_by_group(by_config),
                "by_dataset_size": self._analyze_quality_by_group(by_size)
            },
            "detailed_results": self.results,
            "execution_metadata": self.execution_metadata,
            "timestamp": datetime.now().isoformat()
        }
        
        return consolidated
    
    def _analyze_by_group(self, grouped_results: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """Analisa performance por grupo."""
        analysis = {}
        
        for group_name, results in grouped_results.items():
            times = [r["performance"]["avg_time_ms"] for r in results if r["status"] == "success"]
            
            if times:
                analysis[group_name] = {
                    "count": len(times),
                    "avg_time_ms": statistics.mean(times),
                    "median_time_ms": statistics.median(times),
                    "min_time_ms": min(times),
                    "max_time_ms": max(times),
                    "std_dev_ms": statistics.stdev(times) if len(times) > 1 else 0
                }
        
        return analysis
    
    def _analyze_quality_by_group(self, grouped_results: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """Analisa qualidade por grupo."""
        analysis = {}
        
        for group_name, results in grouped_results.items():
            coverages = []
            keyword_counts = []
            
            for r in results:
                if r["status"] == "success":
                    if "coverage_ratio" in r["quality"].get("coverage", {}):
                        coverages.append(r["quality"]["coverage"]["coverage_ratio"])
                    keyword_counts.append(r["quality"]["keywords_count"])
            
            if coverages or keyword_counts:
                analysis[group_name] = {
                    "count": len(results),
                    "avg_coverage": statistics.mean(coverages) if coverages else 0,
                    "avg_keywords": statistics.mean(keyword_counts) if keyword_counts else 0,
                    "coverage_samples": len(coverages),
                    "keyword_samples": len(keyword_counts)
                }
        
        return analysis
    
    def _save_results(self, consolidated_analysis: Dict[str, Any]) -> str:
        """Salva resultados em arquivo JSON."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Gerar hash dos resultados para detecÃ§Ã£o de mudanÃ§as
        results_str = json.dumps(consolidated_analysis, sort_keys=True, default=str)
        results_hash = hashlib.md5(results_str.encode()).hexdigest()[:8]
        
        filename = f"yake_benchmark_definitivo_{timestamp}_{results_hash}.json"
        output_path = self.output_dir / filename
        
        # Dados a salvar
        output_data = {
            "benchmark_type": "definitivo_robusto",
            "version": "2.0",
            "timestamp": timestamp,
            "results_hash": results_hash,
            "data": consolidated_analysis
        }
        
        # Salvar JSON
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
        
        # Criar link para Ãºltimo resultado
        latest_path = self.output_dir / "latest_benchmark_definitivo.json"
        try:
            if latest_path.exists():
                latest_path.unlink()
            # Criar copy ao invÃ©s de symlink para compatibilidade Windows
            with open(latest_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
        except Exception:
            pass  # Falha silenciosa se nÃ£o conseguir criar link
        
        return str(output_path)
    
    def compare_with_baseline(self, baseline_file: str) -> Dict[str, Any]:
        """
        Compara resultados atuais com baseline.
        
        Args:
            baseline_file: Caminho para arquivo de baseline
            
        Returns:
            AnÃ¡lise comparativa
        """
        try:
            with open(baseline_file, 'r', encoding='utf-8') as f:
                baseline_data = json.load(f)
            
            baseline_results = baseline_data.get("data", {})
            current_results = self._consolidate_analysis()
            
            # ComparaÃ§Ã£o de performance
            performance_comparison = self._compare_performance(
                baseline_results.get("performance", {}),
                current_results.get("performance", {})
            )
            
            # ComparaÃ§Ã£o de qualidade
            quality_comparison = self._compare_quality(
                baseline_results.get("quality", {}),
                current_results.get("quality", {})
            )
            
            return {
                "baseline_file": baseline_file,
                "baseline_timestamp": baseline_data.get("timestamp", "unknown"),
                "current_timestamp": datetime.now().isoformat(),
                "performance": performance_comparison,
                "quality": quality_comparison,
                "summary": self._generate_comparison_summary(performance_comparison, quality_comparison)
            }
            
        except Exception as e:
            return {
                "error": f"Erro ao comparar com baseline: {e}",
                "baseline_file": baseline_file
            }
    
    def _compare_performance(self, baseline: Dict, current: Dict) -> Dict[str, Any]:
        """Compara mÃ©tricas de performance."""
        comparison = {}
        
        # MÃ©tricas principais
        for metric in ["overall_avg_time_ms", "overall_median_time_ms"]:
            if metric in baseline and metric in current:
                baseline_val = baseline[metric]
                current_val = current[metric]
                change = current_val - baseline_val
                change_pct = (change / baseline_val * 100) if baseline_val != 0 else 0
                
                comparison[metric] = {
                    "baseline": baseline_val,
                    "current": current_val,
                    "change": change,
                    "change_percent": change_pct,
                    "improvement": change < 0  # Menor tempo Ã© melhor
                }
        
        return comparison
    
    def _compare_quality(self, baseline: Dict, current: Dict) -> Dict[str, Any]:
        """Compara mÃ©tricas de qualidade."""
        comparison = {}
        
        # MÃ©trica principal de cobertura
        if "overall_avg_coverage" in baseline and "overall_avg_coverage" in current:
            baseline_val = baseline["overall_avg_coverage"]
            current_val = current["overall_avg_coverage"]
            change = current_val - baseline_val
            change_pct = (change / baseline_val * 100) if baseline_val != 0 else 0
            
            comparison["overall_avg_coverage"] = {
                "baseline": baseline_val,
                "current": current_val,
                "change": change,
                "change_percent": change_pct,
                "improvement": change > 0  # Maior cobertura Ã© melhor
            }
        
        return comparison
    
    def _generate_comparison_summary(self, perf_comp: Dict, qual_comp: Dict) -> Dict[str, Any]:
        """Gera resumo da comparaÃ§Ã£o."""
        summary = {
            "performance_status": "unknown",
            "quality_status": "unknown",
            "overall_status": "unknown",
            "recommendations": []
        }
        
        # AnÃ¡lise de performance
        if "overall_avg_time_ms" in perf_comp:
            change_pct = perf_comp["overall_avg_time_ms"]["change_percent"]
            if change_pct < -5:  # Melhoria > 5%
                summary["performance_status"] = "improved"
            elif change_pct > 5:  # DegradaÃ§Ã£o > 5%
                summary["performance_status"] = "degraded"
                summary["recommendations"].append("Investigar degradaÃ§Ã£o de performance")
            else:
                summary["performance_status"] = "stable"
        
        # AnÃ¡lise de qualidade
        if "overall_avg_coverage" in qual_comp:
            change_pct = qual_comp["overall_avg_coverage"]["change_percent"]
            if change_pct > 2:  # Melhoria > 2%
                summary["quality_status"] = "improved"
            elif change_pct < -2:  # DegradaÃ§Ã£o > 2%
                summary["quality_status"] = "degraded"
                summary["recommendations"].append("Investigar degradaÃ§Ã£o de qualidade")
            else:
                summary["quality_status"] = "stable"
        
        # Status geral
        if summary["performance_status"] == "improved" and summary["quality_status"] in ["improved", "stable"]:
            summary["overall_status"] = "improved"
        elif summary["performance_status"] == "degraded" or summary["quality_status"] == "degraded":
            summary["overall_status"] = "degraded"
        else:
            summary["overall_status"] = "stable"
        
        return summary


def main():
    """FunÃ§Ã£o principal do benchmark definitivo."""
    parser = argparse.ArgumentParser(
        description="YAKE Benchmark Definitivo - VersÃ£o Robusta",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python benchmark_definitivo.py                           # Benchmark completo
  python benchmark_definitivo.py --config standard        # Apenas config padrÃ£o
  python benchmark_definitivo.py --dataset tech           # Apenas datasets de tecnologia
  python benchmark_definitivo.py --output results_custom  # Output customizado
  python benchmark_definitivo.py --compare baseline.json  # Comparar com baseline
  python benchmark_definitivo.py --profiling              # Com profiling detalhado
        """
    )
    
    parser.add_argument("--config", help="Filtro para configuraÃ§Ãµes especÃ­ficas")
    parser.add_argument("--dataset", help="Filtro para datasets especÃ­ficos")
    parser.add_argument("--output", default="results", help="DiretÃ³rio de output")
    parser.add_argument("--compare", help="Arquivo baseline para comparaÃ§Ã£o")
    parser.add_argument("--profiling", action="store_true", help="Habilitar profiling detalhado")
    
    args = parser.parse_args()
    
    try:
        # Criar benchmark
        benchmark = BenchmarkDefinitivo(
            output_dir=args.output,
            enable_profiling=args.profiling
        )
        
        # Executar benchmark
        results = benchmark.run_benchmark(
            config_filter=args.config,
            dataset_filter=args.dataset
        )
        
        # ComparaÃ§Ã£o com baseline (se especificado)
        if args.compare:
            print(f"\nðŸ“Š Comparando com baseline: {args.compare}")
            comparison = benchmark.compare_with_baseline(args.compare)
            
            if "error" not in comparison:
                print(f"ðŸ“ˆ Status geral: {comparison['summary']['overall_status']}")
                if comparison['summary']['recommendations']:
                    print("âš ï¸  RecomendaÃ§Ãµes:")
                    for rec in comparison['summary']['recommendations']:
                        print(f"   â€¢ {rec}")
            else:
                print(f"âŒ {comparison['error']}")
        
        print(f"\nðŸŽ‰ Benchmark definitivo concluÃ­do com sucesso!")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  Benchmark interrompido pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Erro durante execuÃ§Ã£o: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()